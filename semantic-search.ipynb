{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12021211,"sourceType":"datasetVersion","datasetId":7563108}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pandas rapidfuzz unidecode sentence-transformers\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-01T06:57:04.323284Z","iopub.execute_input":"2025-06-01T06:57:04.323905Z","iopub.status.idle":"2025-06-01T06:58:26.203781Z","shell.execute_reply.started":"2025-06-01T06:57:04.323879Z","shell.execute_reply":"2025-06-01T06:58:26.203087Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nCollecting rapidfuzz\n  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\nCollecting unidecode\n  Downloading Unidecode-1.4.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\nRequirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.51.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.2)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.31.1)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.2->pandas) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.2->pandas) (2024.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.4.26)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.2->pandas) (2024.2.0)\nDownloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading Unidecode-1.4.0-py3-none-any.whl (235 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.8/235.8 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: unidecode, rapidfuzz, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.10.19\n    Uninstalling nvidia-curand-cu12-10.3.10.19:\n      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\nSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 rapidfuzz-3.13.0 unidecode-1.4.0\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"#you have the fuzzy comabirizon funcion\n#when going over the dataset see score of fuzzy between the normalized version of the name in the dataset \n#and the normaised of the input name \n#if depass score save that og version in the list, then pass that list to llm to get their sneeky ass\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T01:59:48.551194Z","iopub.execute_input":"2025-06-01T01:59:48.551848Z","iopub.status.idle":"2025-06-01T01:59:48.555582Z","shell.execute_reply.started":"2025-06-01T01:59:48.551814Z","shell.execute_reply":"2025-06-01T01:59:48.554788Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import re\ndef normalize(name):\n    stopwords = [\"ste\",\"lab\",\"commerce\",\"electronique\",\"tunisie\",\"service\",\"production\",\"prod\" \"societe\", \"association\",\"société\", \"national\", \"le\", \"la\", \"les\", \"de\", \"du\", \"des\", \"l'\", \"d'\"]\n    \n    # Lowercase the name\n    name = name.lower()\n    \n    # Remove punctuation\n    name = re.sub(r\"[^\\w\\s]\", \" \", name)\n    \n    # Tokenize and remove stopwords\n    tokens = name.split()\n    filtered_tokens = [word for word in tokens if word not in stopwords]\n    \n    # Re-join the cleaned words\n    normalized_name = \" \".join(filtered_tokens)\n    \n    return normalized_name\nprint(normalize(\"Société ISSRAA de Commerce \"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T06:58:37.764776Z","iopub.execute_input":"2025-06-01T06:58:37.765134Z","iopub.status.idle":"2025-06-01T06:58:37.771494Z","shell.execute_reply.started":"2025-06-01T06:58:37.765105Z","shell.execute_reply":"2025-06-01T06:58:37.770658Z"}},"outputs":[{"name":"stdout","text":"issraa\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"from difflib import SequenceMatcher\n\ndef similarity_ratio(a, b):\n    return SequenceMatcher(None, a.lower(), b.lower()).ratio()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T06:58:39.554266Z","iopub.execute_input":"2025-06-01T06:58:39.554927Z","iopub.status.idle":"2025-06-01T06:58:39.558663Z","shell.execute_reply.started":"2025-06-01T06:58:39.554907Z","shell.execute_reply":"2025-06-01T06:58:39.557815Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"#the fuzzy function\nfrom rapidfuzz import fuzz, process\n\n\n#the fuzz score counts similarity in character by character space do no make difference\n\n\ndef get_fuzz_score(input_user, dataset_name, threshold=60):\n    \"\"\"\n    function take the user name and a name from dataset and get fuzz score of the normalised names\n    \"\"\"\n    input_norm = normalize(input_user)\n    dataset_norm = normalize(dataset_name)\n    #print(f\"the words we will fuzz {input_norm}  and {dataset_norm}\")\n    # Calculate different types of fuzzy scores\n    #score_set = fuzz.token_set_ratio(input_norm, dataset_norm)\n    #score_sort = fuzz.token_sort_ratio(input_norm, dataset_norm)\n    #score_partial = fuzz.partial_ratio(input_norm, dataset_norm)\n\n    # Average score (you can also weight them)\n    #avg_score = (score_set + score_sort + score_partial) / 3\n    \n    #print(f\"Normalized: '{input_norm}' vs '{dataset_norm}'\")\n    #print(f\"token_set: {score_set}, token_sort: {score_sort}, partial: {score_partial}, avg: {avg_score:.1f}\")\n    return similarity_ratio(input_norm,dataset_norm)\n    #if avg_score > threshold:\n        #print(f\"🔍 POSSIBLE MATCH: '{input_user}' vs '{dataset_name} seems too close need llm'\\n\")\n       # return True\n   # else:\n        #print(f\"❌ Not similar enough can pass, no need to llm.\\n\")\n     #   return False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T06:58:41.368028Z","iopub.execute_input":"2025-06-01T06:58:41.368560Z","iopub.status.idle":"2025-06-01T06:58:41.390695Z","shell.execute_reply.started":"2025-06-01T06:58:41.368540Z","shell.execute_reply":"2025-06-01T06:58:41.389980Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"get_fuzz_score(\"Injaz prod \",\"Injaz prod \")\nget_fuzz_score(\"noor \",\"nour\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T06:58:44.036677Z","iopub.execute_input":"2025-06-01T06:58:44.036984Z","iopub.status.idle":"2025-06-01T06:58:44.043113Z","shell.execute_reply.started":"2025-06-01T06:58:44.036963Z","shell.execute_reply":"2025-06-01T06:58:44.042511Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"0.75"},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"### now given a words go over the dataset and get all the words that pass the threshold anc would need llm to verify","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport re\nfrom unidecode import unidecode\nfrom rapidfuzz import fuzz\n\n# Load your Excel\ndf = pd.read_excel(\"/kaggle/input/godhelpmeiamtired/Sample_100k.xlsx\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T06:59:33.724415Z","iopub.execute_input":"2025-06-01T06:59:33.725050Z","iopub.status.idle":"2025-06-01T06:59:40.625518Z","shell.execute_reply.started":"2025-06-01T06:59:33.725027Z","shell.execute_reply":"2025-06-01T06:59:40.624879Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"arabic_names = df[\"NOM_AR\"].dropna().astype(str).tolist()\nfrench_names = df[\"NOM_FR\"].dropna().astype(str).tolist()\nprint(len(arabic_names),len(french_names))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T06:59:40.626696Z","iopub.execute_input":"2025-06-01T06:59:40.626959Z","iopub.status.idle":"2025-06-01T06:59:40.666429Z","shell.execute_reply.started":"2025-06-01T06:59:40.626940Z","shell.execute_reply":"2025-06-01T06:59:40.665485Z"}},"outputs":[{"name":"stdout","text":"100000 100000\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"### plz why","metadata":{}},{"cell_type":"markdown","source":"### it starts here","metadata":{}},{"cell_type":"code","source":"user_name = \"Injaz production \"\nprint(get_fuzz_score(\"isra\",\"DWIRA\"))\ndef jaccard_similarity(str1, str2):\n    set1 = set(str1.lower().split())\n    set2 = set(str2.lower().split())\n    return len(set1 & set2) / len(set1 | set2)\nprint(jaccard_similarity(\"isra comerce\",\"isra commerce\"))\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\ndef tfidf_similarity(text1, text2):\n    vec = TfidfVectorizer().fit([text1, text2])\n    tfidf = vec.transform([text1, text2])\n    return cosine_similarity(tfidf[0], tfidf[1])[0][0]\nprint(tfidf_similarity(\"isra comerce\",\"isra commerce\"))\nfrom difflib import SequenceMatcher\n\ndef similarity_ratio(a, b):\n    return SequenceMatcher(None, a.lower(), b.lower()).ratio()\nprint(similarity_ratio(\"isra comerce\",\"isra commerce\"))\nprint(similarity_ratio(\"isra \",\"issmara\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T06:59:44.670482Z","iopub.execute_input":"2025-06-01T06:59:44.670784Z","iopub.status.idle":"2025-06-01T06:59:44.733398Z","shell.execute_reply.started":"2025-06-01T06:59:44.670764Z","shell.execute_reply":"2025-06-01T06:59:44.732574Z"}},"outputs":[{"name":"stdout","text":"0.6666666666666666\n0.3333333333333333\n0.33609692727625756\n0.96\n0.6666666666666666\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"list_candidates=[]\nfor word in french_names:\n    if get_fuzz_score(user_name,word)>0.7:\n        #print(word)\n        list_candidates.append(word)\nprint(list_candidates)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T06:59:47.308863Z","iopub.execute_input":"2025-06-01T06:59:47.309578Z","iopub.status.idle":"2025-06-01T06:59:49.289258Z","shell.execute_reply.started":"2025-06-01T06:59:47.309557Z","shell.execute_reply":"2025-06-01T06:59:49.288325Z"}},"outputs":[{"name":"stdout","text":"['Finjan', 'société injah', 'INJAZ']\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"llm_prompt_template = \"\"\"\nYou are a system that detects whether a user-submitted company name is a slightly altered or intentionally modified version of any known company names in a given list.\n\nThe goal is to detect subtle modifications such as:\n- Swapping similar-sounding letters or syllables (e.g., \"Noor\" vs \"Nour\")\n- Transliteration changes\n- Phonetic tricks\n\nTask:\nYou will receive:\n- A user-submitted company name\n- A list of known company names\n\nYour job is to tell me which known name(s), if any, the user-submitted name is likely trying to imitate with small changes.\nTake in consideration the semantic meaning of the words if they logically cant be describing to the same company then dont include it\nOutput format:\nRespond with one of the following:\n- YES: [Matching_Name_1, Matching_Name_2]\n- NO\n\n\nNow analyze this:\nUser-submitted name: {user_name}\nKnown names:\n{known_names}\n\"\"\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T06:59:52.024507Z","iopub.execute_input":"2025-06-01T06:59:52.025060Z","iopub.status.idle":"2025-06-01T06:59:52.029033Z","shell.execute_reply.started":"2025-06-01T06:59:52.025031Z","shell.execute_reply":"2025-06-01T06:59:52.028257Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"known_names_str = \"\\n\".join(f\"- {name}\" for name in list_candidates)\nprompt = llm_prompt_template.format(user_name=user_name, known_names=known_names_str)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T06:59:54.056211Z","iopub.execute_input":"2025-06-01T06:59:54.056951Z","iopub.status.idle":"2025-06-01T06:59:54.060634Z","shell.execute_reply.started":"2025-06-01T06:59:54.056926Z","shell.execute_reply":"2025-06-01T06:59:54.060004Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"prompt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T06:59:57.659225Z","iopub.execute_input":"2025-06-01T06:59:57.659519Z","iopub.status.idle":"2025-06-01T06:59:57.664807Z","shell.execute_reply.started":"2025-06-01T06:59:57.659493Z","shell.execute_reply":"2025-06-01T06:59:57.664061Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"'\\nYou are a system that detects whether a user-submitted company name is a slightly altered or intentionally modified version of any known company names in a given list.\\n\\nThe goal is to detect subtle modifications such as:\\n- Swapping similar-sounding letters or syllables (e.g., \"Noor\" vs \"Nour\")\\n- Transliteration changes\\n- Phonetic tricks\\n\\nTask:\\nYou will receive:\\n- A user-submitted company name\\n- A list of known company names\\n\\nYour job is to tell me which known name(s), if any, the user-submitted name is likely trying to imitate with small changes.\\nTake in consideration the semantic meaning of the words if they logically cant be describing to the same company then dont include it\\nOutput format:\\nRespond with one of the following:\\n- YES: [Matching_Name_1, Matching_Name_2]\\n- NO\\n\\n\\nNow analyze this:\\nUser-submitted name: Injaz production \\nKnown names:\\n- Finjan\\n- société injah\\n- INJAZ\\n'"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"from google import genai\n\nclient = genai.Client(api_key=\"AIzaSyC6yHwqS0J-5SZP7SNMoBxxfrGjK8a-5rk\")\n\nresponse = client.models.generate_content(\n    model=\"gemini-2.0-flash\",\n    contents=prompt,\n)\n\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T02:50:37.149981Z","iopub.execute_input":"2025-06-01T02:50:37.150266Z","iopub.status.idle":"2025-06-01T02:50:37.884411Z","shell.execute_reply.started":"2025-06-01T02:50:37.150245Z","shell.execute_reply":"2025-06-01T02:50:37.883595Z"}},"outputs":[{"name":"stdout","text":"YES: [INJAZ]\n\n","output_type":"stream"}],"execution_count":91},{"cell_type":"code","source":"from google import genai\n\nclient = genai.Client(api_key=\"AIzaSyC6yHwqS0J-5SZP7SNMoBxxfrGjK8a-5rk\")\n\ndef return_similair(worduser):\n    list_candidates=[]\n    for word in french_names:\n        if get_fuzz_score(worduser,word)>0.7:\n            #print(word)\n            list_candidates.append(word)\n    known_names_str = \"\\n\".join(f\"- {name}\" for name in list_candidates)\n    prompt = llm_prompt_template.format(user_name=worduser, known_names=known_names_str)\n    response = client.models.generate_content(\n    model=\"gemini-2.0-flash\",\n    contents=prompt,\n    )\n    \n    print(response.text)\n\n#return_similair(\"TRADECO\")\n#YES: [TRADERCO, TRADECO SARL, TRADCO]\n#return_similair(\"Stidma\") #Stedma\n#YES: [Istidama, SITMA, Stedma]\n\n#TUNISIE SIRIENE PLUS AUTO CASSE\n#return_similair(\"TUNISIE SIRIENE PLUS AUTO CASSE\") \n#YES: [TUNISIE SIRIENE PLUS AUTO CASSE, TUNISIE SIRIENE AUTO CASSE]\nreturn_similair(\"Noor\")  #[Cosy Food, CRAZY WOOD]\n#after this add semantic ?\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T07:00:24.481163Z","iopub.execute_input":"2025-06-01T07:00:24.481706Z","iopub.status.idle":"2025-06-01T07:00:27.835628Z","shell.execute_reply.started":"2025-06-01T07:00:24.481684Z","shell.execute_reply":"2025-06-01T07:00:27.834846Z"}},"outputs":[{"name":"stdout","text":"YES: [Nour, Société Nour]\n\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nmodel = SentenceTransformer('all-MiniLM-L6-v2')\n\ndef semantic_similarity(text1, text2):\n    embeddings = model.encode([text1, text2])\n    score = cosine_similarity([embeddings[0]], [embeddings[1]])[0][0]\n    return score  # Between 0 and 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T03:27:15.165299Z","iopub.execute_input":"2025-06-01T03:27:15.165959Z","iopub.status.idle":"2025-06-01T03:27:21.450157Z","shell.execute_reply.started":"2025-06-01T03:27:15.165934Z","shell.execute_reply":"2025-06-01T03:27:21.449516Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5156e0db5f7d4199b6aa4f9b5cf3101a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb0692abd6b24093b68c897b12be8003"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c35e9c3ee1474da3868fb70d8ec871be"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7fea7dd099a64eb4adba523198fddcbd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"230762aeec5944b1a25dafc3cffb9378"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88fcce9f9ed247aeb7592d6291544bf8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e844846c41f49ab869a4394e33d97c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e4f95ca42ec4431b9da0ae29f2dc53f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dcf5d70cfb74464fa3f1faff0bf69320"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7623c89959d4ff397b7071412b77fe8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d291f0468554f5bb661b4c603edfa2e"}},"metadata":{}}],"execution_count":107},{"cell_type":"code","source":"#print(semantic_similarity(\"Crazy food\",\"Cosy Food\")) #theshold on the 80 if above 80 we have problem\n#[STE TAHA ELECTRO, Societe Dridi Electronique, AIK ELECTRONIQUE]\n#CSTE TAha ELECTROnique\nprint(semantic_similarity(\"CSTE TAHA ELECTROnique\",\"CSTE TAHA ELECTROnique\"))\n\nprint(semantic_similarity(\"CSTE TAHA ELECTROnique\",\"STE TAHA ELECTRO\"))\nprint(semantic_similarity(\"CSTE TAha ELECTROnique\",\"Societe Dridi Electronique\"))\nprint(semantic_similarity(\"CSTE TAha ELECTROnique\",\"AIK ELECTRONIQUE\"))\n#maybe not\n#pass to another fucking llm ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T03:32:18.518611Z","iopub.execute_input":"2025-06-01T03:32:18.518945Z","iopub.status.idle":"2025-06-01T03:32:18.615112Z","shell.execute_reply.started":"2025-06-01T03:32:18.518922Z","shell.execute_reply":"2025-06-01T03:32:18.614214Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf45c789f9eb4b94a3644a5980f052bf"}},"metadata":{}},{"name":"stdout","text":"0.9999998\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e51d78f2aa464639acefd76cb0d4957c"}},"metadata":{}},{"name":"stdout","text":"0.48604053\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01edd360df304eb4a91ba0b891ecae81"}},"metadata":{}},{"name":"stdout","text":"0.4895613\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a0cd6f31f54a4237bed2e8f518a409ed"}},"metadata":{}},{"name":"stdout","text":"0.6474776\n","output_type":"stream"}],"execution_count":115},{"cell_type":"code","source":"from google import genai\n\n#take the list from above and 3ewed 3addi 3al model\ndef final_review(username, listnames):\n    # Initialize Gemini client with your API key\n    client = genai.Client(api_key=\"AIzaSyC6yHwqS0J-5SZP7SNMoBxxfrGjK8a-5rk\")\n\n    # Create a clear, specific prompt\n    prompt = (\n        f\"You are an expert on RNE Tunisia startup name registration. \"\n        f\"A user wants to register the name: '{username}'.\\n\"\n        f\"Here are some existing similar names in the database:\\n{listnames}\\n\\n\"\n         f\"Only say 'REJECTED' if the proposed name is almost identical in spelling or structure to one of the existing names — for example, if it only differs by 1 or 2 letters, or it looks nearly the same when written.\\n\"\n    f\"If the name is just vaguely similar or uses common words, say 'ACCEPTED'.\\n\"\n    f\"\\nAnswer with only one word: either 'ACCEPTED' or 'REJECTED'.\"\n    )\n\n    # Generate response using Gemini Flash\n    response = client.models.generate_content(\n        model=\"gemini-2.0-flash\",\n        contents=prompt\n    )\n\n    print(response.text.strip())\nfinal_review(\"noor\",[\"Nour\", \"Société Nour\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T07:02:21.207320Z","iopub.execute_input":"2025-06-01T07:02:21.208154Z","iopub.status.idle":"2025-06-01T07:02:21.702413Z","shell.execute_reply.started":"2025-06-01T07:02:21.208129Z","shell.execute_reply":"2025-06-01T07:02:21.701747Z"}},"outputs":[{"name":"stdout","text":"REJECTED\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"!pip install anthropic","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T03:52:49.729163Z","iopub.execute_input":"2025-06-01T03:52:49.729458Z","iopub.status.idle":"2025-06-01T03:52:53.737271Z","shell.execute_reply.started":"2025-06-01T03:52:49.729438Z","shell.execute_reply":"2025-06-01T03:52:53.736444Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting anthropic\n  Downloading anthropic-0.52.1-py3-none-any.whl.metadata (25 kB)\nRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (4.9.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.28.1)\nRequirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.9.0)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (2.11.4)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.3.1)\nRequirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from anthropic) (4.13.2)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.10)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->anthropic) (2025.4.26)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->anthropic) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic) (0.14.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.4.0)\nDownloading anthropic-0.52.1-py3-none-any.whl (286 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.1/286.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: anthropic\nSuccessfully installed anthropic-0.52.1\n","output_type":"stream"}],"execution_count":124},{"cell_type":"markdown","source":"### teh social impact part","metadata":{}},{"cell_type":"code","source":"qwen_api=\"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\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T03:57:08.592521Z","iopub.execute_input":"2025-06-01T03:57:08.593140Z","iopub.status.idle":"2025-06-01T03:57:08.596726Z","shell.execute_reply.started":"2025-06-01T03:57:08.593113Z","shell.execute_reply":"2025-06-01T03:57:08.596095Z"}},"outputs":[],"execution_count":129},{"cell_type":"code","source":"def social_impact():\n        import requests\n        import json\n        \n        response = requests.post(\n          url=\"https://openrouter.ai/api/v1/chat/completions\",\n          headers={\n            \"Authorization\": \"Bearer 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\",\n            \"Content-Type\": \"application/json\",\n          },\n          data=json.dumps({\n            \"model\": \"qwen/qwq-32b:free\",\n            \"messages\": [\n              {\n                \"role\": \"user\",\n                \"content\": \"What is the meaning of life?\"\n              }\n            ],\n            \n          })\n        )\n        print(response)\nsocial_impact()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T03:59:42.800786Z","iopub.execute_input":"2025-06-01T03:59:42.801392Z","iopub.status.idle":"2025-06-01T04:00:34.098761Z","shell.execute_reply.started":"2025-06-01T03:59:42.801369Z","shell.execute_reply":"2025-06-01T04:00:34.097711Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/2334098298.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m         )\n\u001b[1;32m     22\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0msocial_impact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_35/2334098298.py\u001b[0m in \u001b[0;36msocial_impact\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         response = requests.post(\n\u001b[0m\u001b[1;32m      6\u001b[0m           \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"https://openrouter.ai/api/v1/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m           headers={\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \"\"\"\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mcontent\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    900\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONTENT_CHUNK_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content_consumed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"stream\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m                     \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mChunkedEncodingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1061\u001b[0m         \"\"\"\n\u001b[1;32m   1062\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunked\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupports_chunked_reads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_fp_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decoded_buffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread_chunked\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_chunk_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_update_chunk_length\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1136\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1138\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[union-attr]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1139\u001b[0m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb\";\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1312\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1314\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1167\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":132},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}